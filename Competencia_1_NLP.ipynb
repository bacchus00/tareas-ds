{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aK24MJ8jzvIr",
        "FevBPus0zvIs",
        "gmMdm98vzvIy"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bacchus00/tareas-ds/blob/main/Competencia_1_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:49:08.174519Z",
          "start_time": "2020-03-31T13:49:08.165989Z"
        },
        "id": "gpbvNOH0zvIi"
      },
      "source": [
        "# **Competencia 1 - CC6205 Natural Language Processing üìö**\n",
        "\n",
        "**Integrantes:** Ricardo Garc√≠a, Nicol√°s Canales, Melanie Marquez, Franc Zautzik\n",
        "\n",
        "**Usuario del equipo en CodaLab:** FraNiMeRi\n",
        "\n",
        "**Fecha l√≠mite de entrega üìÜ:** Jueves 14 de Abril.\n",
        "\n",
        "**Tiempo estimado de dedicaci√≥n:** 20 hrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxlNrNf_p0ZY"
      },
      "source": [
        "## **Objetivo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrtvsKf2p3A4"
      },
      "source": [
        "En esta tarea grupal participar√°n de una competencia estilo [Kaggle](https://www.kaggle.com/) pero utilizando la p√°gina [CodaLab](https://codalab.org/). El objetivo es trabajar en la clasificaci√≥n de tweets  seg√∫n su intensidad de emoci√≥n, esto corresponde a la task de clasificaci√≥n de texto. \n",
        "\n",
        "Tendr√°n a su disposici√≥n 4 datasets de tweets con distintas emociones: `anger`, `fear`, `sadness` y `joy`. Deber√°n crear un clasificador para cada uno de estos datasets que indique la intensidad de dicha emoci√≥n en sus tweets (`low`, `medium`, `high`). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6lhhfl2zvIk"
      },
      "source": [
        "## **Instrucciones**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T14:34:38.796217Z",
          "start_time": "2020-04-07T14:34:38.782255Z"
        },
        "id": "7wTyult1zvIl"
      },
      "source": [
        "- La competencia consiste en resolver 4 problemas de clasificaci√≥n **distintos**, cada uno con tres clases posibles. Por cada problema deber√°n crear un clasificador distinto. La evaluaci√≥n de la competencia se realiza en base a 3 m√©tricas: `AUC`, `Kappa` y `Accuracy`. Los mejores puntajes en cada una de estas m√©tricas ser√°n quienes ganen la competencia.\n",
        "\n",
        "- Para comenzar se les entregar√° en este notebook la estructura del informe a entregar y el c√≥digo de un baseline con el cu√°l pueden comparar los resultados de sus experimentos. Este baseline consiste en la creaci√≥n de features y una clasificaci√≥n simple siguiendo el paradigma de Machine Learning emp√≠rico. Los puntajes obtenidos por el baseline los pueden visualizar en el link de CodaLab buscando al usuario **cc6205**. Esperamos que los superen f√°cilmente üòâ\n",
        "\n",
        "- Para participar, deben registrarse en CodaLab y luego ingresar a la competencia usando el siguiente [link](https://competitions.codalab.org/competitions/30330?secret_key=b2ed0be7-bf23-42a1-9400-f85fa1b7bae7). \n",
        "\n",
        "- Est√° permitido hacer grupos de m√°ximo 4 alumnos. Cada grupo debe tener un nombre de equipo, para ello en CodaLab pueden dirigirse a settings y luego cambiar el Team Name. S√≥lo una persona debe administrar la cuenta del grupo y se verificar√° que no se hayan creado m√∫ltiples cuentas por grupo.\n",
        "\n",
        "- En total pueden hacer un **m√°ximo de 4 submissions**, hagan muchos experimentos probando en el conjunto de test antes de realizar el env√≠o.\n",
        "\n",
        "- Es importante que hagan varios experimentos incorporando t√©cnicas como [cross-validation](https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada#:~:text=La%20validaci%C3%B3n%20cruzada%20o%20cross,datos%20de%20entrenamiento%20y%20prueba.) o [random sampling](https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c) antes de enviar sus predicciones a CodaLab, ya que les puede dar un mejor indicio del nivel de generalizaci√≥n de sus modelos. \n",
        "\n",
        "- Aseg√∫rense que la distribuci√≥n de las clases sea balanceada en las particiones de training y testing debido a que existe un desbalanceo. \n",
        "\n",
        "- Verificar que el formato de la submission coincida con el de la competencia. De lo contrario, se les ser√° evaluado incorrectamente ya que el Script de evaluaci√≥n espera como input dicho formato. En el c√≥digo de las m√©tricas pueden verificar c√≥mo son los inputs.\n",
        "\n",
        "- No se limiten a los contenidos vistos ni a scikit ni a este baseline. No tienen restricciones entre utilizar Deep Learning o Machine Learning emp√≠rico. Si reutilizan gran cantidad de c√≥digo de alguna p√°gina por favor mostrar la referencia en su c√≥digo. ¬°Usen todo su conocimiento e ingenio en mejorar sus sistemas para poder ganar la competencia! \n",
        "\n",
        "- **Es requisito entregar el reporte con el c√≥digo y haber participado en la competencia para ser evaluado. Un c√≥digo sin reporte o un reporte sin c√≥digo ser√°n evaluados con la nota m√≠nima.**\n",
        "\n",
        "- Todas las dudas escr√≠banlas en el canal de Discord de competencias. Los emails que lleguen al equipo docente ser√°n remitidos a ese medio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:25:19.677190Z",
          "start_time": "2020-04-07T15:25:19.671206Z"
        },
        "id": "jiDISxa-zvIn"
      },
      "source": [
        "**Importante**: Recuerden poner su nombre y el de su usuario o de equipo (en caso de que aplique) en el reporte. NO ser√°n evaluados Notebooks sin nombre."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igf7TBfSzvIo"
      },
      "source": [
        "----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6moqxkEwCe-"
      },
      "source": [
        "## **Reporte a entregar**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo7vfXV4wD8s"
      },
      "source": [
        "Uno de los puntos claves en la evaluaci√≥n de esta competencia es elaborar un informe claro y preciso, argumentando las decisiones tomadas al momento de crear sus modelos para que el cuerpo docente pueda entenderlos. La estructura que debe contener es la siguiente:\n",
        "\n",
        "1.\t**Introducci√≥n**: Presentar brevemente el problema a resolver, incluyendo la formalizaci√≥n de la task (c√≥mo son los inputs y outputs del problema) y los desaf√≠os que ven al analizar el corpus entregado. (**0.5 puntos**)\n",
        "2.\t**Representaciones**: Describir los atributos y representaciones usadas como entrada de los clasificadores, **recordar** que para entrenar modelos el input debe tener su representaci√≥n num√©rica. Si bien, con Bag of Words (**baseline**) ya se comienzan a percibir buenos resultados, pueden mejorar su evaluaci√≥n agregando m√°s atributos y representaciones dise√±adas a mano, sean lo m√°s creativos posible. M√°s abajo encontrar√°n una lista de estos posibles atributos que les podr√° ser de utilidad. (**1 punto**)\n",
        "3.\t**Algoritmos**: Describir **brevemente** los algoritmos de clasificaci√≥n usados, tanto si fueron algoritmos ya vistos en clases o bien arquitecturas de Deep Learning. (**0.5 puntos**)\n",
        "4.\t**M√©tricas de evaluaci√≥n**: Describir brevemente las m√©tricas utilizadas en la evaluaci√≥n, indicando qu√© miden y su interpretaci√≥n. (**0.5 puntos**)\n",
        "\n",
        "5.  **Dise√±o experimental**: Esta es una de las secciones m√°s importantes del reporte. Deben describir minuciosamente los experimentos que realizar√°n en la siguiente secci√≥n. Describir las variables de control que manejar√°n, algunos ejemplos pueden ser: Los par√°metros de los clasificadores, par√°metros en las funciones con que procesan los textos y los transforman, par√°metros para el cross-validation, particiones de datos utilizadas, etc. En caso que utilicen redes neuronales, ser claros con el conjunto de hiperpar√°metros que probar√°n, la decisi√≥n en las funciones de optimizaci√≥n, funci√≥n de p√©rdida,  regulaci√≥n, etc. B√°sicamente explicar qu√© es lo que veremos en la siguiente secci√≥n.\n",
        "(**1 punto**)\n",
        "\n",
        "6.\t**Experimentos**: Incluyan todo el c√≥digo de sus experimentos aqu√≠. ¬°Es vital haber realizado varios experimentos para sacar una buena nota! (**1.5 puntos**)\n",
        "\n",
        "7. **Resultados**: Comparar los resultados obtenidos utilizando diferentes algoritmos y representaciones.  Pueden mostrar los resultados sobre la partici√≥n de validaci√≥n en caso que la generen o sobre los resultados del conjunto de testing. Mostrar los resultados en alguna tabla, pueden poner aqu√≠ tambi√©n los resultados obtenidos al realizar la submission. (**0.5 puntos**)\n",
        "\n",
        "8. **Conclusiones**:  Discutir resultados, proponer trabajo futuro. (**0.5 puntos**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMSn_tDYwOb1"
      },
      "source": [
        "## **Descripci√≥n Baseline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-21T19:18:43.301002Z",
          "start_time": "2019-08-21T19:18:43.298037Z"
        },
        "id": "30fPWG5pzvIm"
      },
      "source": [
        "` `\n",
        "El baseline de la secci√≥n **Experimentos** contiene un c√≥digo b√°sico que resuelve la task y es el modelo subido por **cc6205-baseline** a la competencia. Pueden modificar el c√≥digo como quieran siempre y cuando no cambien las funciones de las m√©tricas y el formato en que se suben los archivos a la competencia, ya que ese es el formato en que realizamos la evaluaci√≥n. En concretro, el baseline hace lo siguiente:\n",
        "` `\n",
        "\n",
        "- Obtiene los datasets desde el repositorio del curso.\n",
        "- Divide los datasets en train (datos que est√°n etiquetados) y target set (datos no etiquetados para la competencia). Adem√°s, por cada dataset en train, se divide en un conjunto de entrenamiento y uno de prueba. Aqu√≠ la mejor pr√°ctica ser√≠a cambiar el c√≥digo para obtener un conjunto de entrenamiento, validaci√≥n y prueba.\n",
        "\n",
        "- Crea un Pipeline que: \n",
        "    - Crea features personalizados para la representaci√≥n num√©rica.\n",
        "    - Transforma los dataset a bag of words (BoW).  \n",
        "    - Entrena un clasificador usando cada train set.\n",
        "- Clasifica y evalua el sistema creado usando el test set.\n",
        "- Clasifica el target set.\n",
        "- Genera una submission con el target en formato zip en el directorio en donde se est√° ejecutando el notebook. \n",
        "\n",
        "` `\n",
        "\n",
        "Algunas pistas sobre como mejorar el rendimiento de los sistemas que creen. (Esto tendr√° mas sentido cuando vean el c√≥digo)\n",
        "\n",
        "- **Vectorizador**: Investigar los modulos de `nltk`, en particular, `TweetTokenizer`, `mark_negation` para reemplazar los tokenizadores. Tambi√©n, el par√°metro `ngram_range` (Ojo que el clf naive bayes no deber√≠a usarse con n-gramas, ya que rompe el supuesto de independencia). Adem√°s, implementar los atributos que crean √∫tiles desde el listado del enunciado. Investigar tambi√©n el vectorizador tf-idf.\n",
        "\n",
        "- **Clasificador**: Investigar otros clasificadores m√°s efectivos que naive bayes. Estos deben poder retornar la probabilidad de pertenecia de las clases (ie: implementar la funci√≥n `predict_proba`).\n",
        "\n",
        "- **Features**: Recuerden que pueden implementar todas las features que se les ocurra! Aqu√≠ les adjuntamos algunos ejemplos:\n",
        "    -\tWord n-grams.\n",
        "    -\tCharacter n-grams. \n",
        "    -\tPart-of-speech tags.\n",
        "    -\tSentiment Lexicons (Lexicon = A set of words with a label or associated value.).\n",
        "        - Count the number of positive and negative words within a sentence.\n",
        "        - If the lexicon has associated intensity of feeling (for example in a decimal), then take the average of the intensity of the sentence according to the feeling, the sum, etc.\n",
        "        -\tA good lexicon of sentiment: [Bing Liu](http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar) \n",
        "        - A reference with a lot of [sentiment lexicons](https://medium.com/@datamonsters/sentiment-analysis-tools-overview-part-1-positive-and-negative-words-databases-ae35431a470c). \n",
        "    -\tThe number of elongated words (words with one character repeated more than two times).\n",
        "    -\tThe number of words with all characters in uppercase.\n",
        "    -\tThe presence and the number of positive or negative emoticons.\n",
        "    -\tThe number of individual negations.\n",
        "    -\tThe number of contiguous sequences of dots, question marks and exclamation marks.\n",
        "    -\tWord Embeddings: Here are some good ideas on how to use them.\n",
        "    https://stats.stackexchange.com/questions/221715/apply-word-embeddings-to-entire-document-to-get-a-feature-vector\n",
        "\n",
        "- **Reducci√≥n de dimensionalidad**: Tambi√©n puede serles de ayuda. Referencias [aqu√≠](https://scikit-learn.org/stable/modules/unsupervised_reduction.html).\n",
        "\n",
        "- Por √∫ltimo, pueden encontrar mas referencias de c√≥mo mejorar sus features, el vectorizador y el clasificador [aqu√≠](https://affectivetweets.cms.waikato.ac.nz/benchmark/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT7ZpVRuzGAF"
      },
      "source": [
        "# **Entregable.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:34:25.683540Z",
          "start_time": "2020-03-31T13:34:25.673430Z"
        },
        "id": "E29LEMZ9zvIo"
      },
      "source": [
        "## **1. Introducci√≥n**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W20NnoduzvIo"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:47:13.474238Z",
          "start_time": "2020-03-31T13:47:13.454068Z"
        },
        "id": "OTAIEnSJzvIp"
      },
      "source": [
        "## **2. Representaciones**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:47:17.719268Z",
          "start_time": "2020-03-31T13:47:17.709207Z"
        },
        "id": "EV1qBv-MzvIp"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMOjYSQezvIq"
      },
      "source": [
        "## **3. Algoritmos**\n",
        "\n",
        "> Bloc con sangr√≠a\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bPiFs33zilS"
      },
      "source": [
        "    Explique los algoritmos utilizados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:47:52.064631Z",
          "start_time": "2020-03-31T13:47:52.044451Z"
        },
        "id": "ECjkdgdwzvIq"
      },
      "source": [
        "## **4. M√©tricas de Evaluaci√≥n**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6eHJdHBzvIr"
      },
      "source": [
        "- AUC: ...\n",
        "- Kappa: ...\n",
        "- Accuracy: ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJyTrr2onLOo"
      },
      "source": [
        "## **5. Dise√±o experimental**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnhEwjh_nP9M"
      },
      "source": [
        "    Descripci√≥n de la metodolog√≠a "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX5Ib_pCzvIr"
      },
      "source": [
        "## **6. Experimentos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-31T13:31:40.023344Z",
          "start_time": "2020-03-31T13:31:40.003541Z"
        },
        "id": "aK24MJ8jzvIr"
      },
      "source": [
        "### Importar librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:20.587160Z",
          "start_time": "2020-04-07T15:44:19.319386Z"
        },
        "id": "FukgFUTUzvIs"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.metrics import confusion_matrix, cohen_kappa_score, classification_report, accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FevBPus0zvIs"
      },
      "source": [
        "### Definir m√©todos de evaluaci√≥n (**NO tocar este c√≥digo**)\n",
        "\n",
        "Estas funciones est√°n a cargo de evaluar los resultados de la tarea. No deber√≠an cambiarlas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:20.604066Z",
          "start_time": "2020-04-07T15:44:20.589106Z"
        },
        "id": "9wlllV7PzvIs"
      },
      "source": [
        "def auc_score(test_set, predicted_set):\n",
        "    high_predicted = np.array([prediction[2] for prediction in predicted_set])\n",
        "    medium_predicted = np.array(\n",
        "        [prediction[1] for prediction in predicted_set])\n",
        "    low_predicted = np.array([prediction[0] for prediction in predicted_set])\n",
        "    high_test = np.where(test_set == 'high', 1.0, 0.0)\n",
        "    medium_test = np.where(test_set == 'medium', 1.0, 0.0)\n",
        "    low_test = np.where(test_set == 'low', 1.0, 0.0)\n",
        "    auc_high = roc_auc_score(high_test, high_predicted)\n",
        "    auc_med = roc_auc_score(medium_test, medium_predicted)\n",
        "    auc_low = roc_auc_score(low_test, low_predicted)\n",
        "    auc_w = (low_test.sum() * auc_low + medium_test.sum() * auc_med +\n",
        "             high_test.sum() * auc_high) / (\n",
        "                 low_test.sum() + medium_test.sum() + high_test.sum())\n",
        "    return auc_w\n",
        "\n",
        "\n",
        "def evaluate(predicted_probabilities, y_test, labels, dataset_name):\n",
        "    # Importante: al transformar los arreglos de probabilidad a clases,\n",
        "    # entregar el arreglo de clases aprendido por el clasificador.\n",
        "    # (que comunmente, es distinto a ['low', 'medium', 'high'])\n",
        "    predicted_labels = [\n",
        "        labels[np.argmax(item)] for item in predicted_probabilities\n",
        "    ]\n",
        "\n",
        "    print('Confusion Matrix for {}:\\n'.format(dataset_name))\n",
        "    print(\n",
        "        confusion_matrix(y_test,\n",
        "                         predicted_labels,\n",
        "                         labels=['low', 'medium', 'high']))\n",
        "\n",
        "    print('\\nClassification Report:\\n')\n",
        "    print(\n",
        "        classification_report(y_test,\n",
        "                              predicted_labels,\n",
        "                              labels=['low', 'medium', 'high']))\n",
        "    # Reorder predicted probabilities array.\n",
        "    labels = labels.tolist()\n",
        "    \n",
        "    predicted_probabilities = predicted_probabilities[:, [\n",
        "        labels.index('low'),\n",
        "        labels.index('medium'),\n",
        "        labels.index('high')\n",
        "    ]]\n",
        "    \n",
        "    \n",
        "    auc = round(auc_score(y_test, predicted_probabilities), 3)\n",
        "    print(\"Scores:\\n\\nAUC: \", auc, end='\\t')\n",
        "    kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
        "    print(\"Kappa:\", kappa, end='\\t')\n",
        "    accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print('------------------------------------------------------\\n')\n",
        "    return np.array([auc, kappa, accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkOP6ugwzvIt"
      },
      "source": [
        "### Datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.068137Z",
          "start_time": "2020-04-07T15:44:20.606061Z"
        },
        "id": "D1XhFPhrzvIt"
      },
      "source": [
        "# Datasets de entrenamiento.\n",
        "train = {\n",
        "    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/anger-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
        "    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/fear-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
        "    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/joy-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
        "    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/sadness-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'])\n",
        "}\n",
        "\n",
        "# Datasets que deber√°n predecir para la competencia.\n",
        "target = {\n",
        "    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/anger-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
        "    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/fear-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
        "    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/joy-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
        "    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/sadness-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE'])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.088707Z",
          "start_time": "2020-04-07T15:44:21.069757Z"
        },
        "id": "flg2Zw2mzvIt"
      },
      "source": [
        "# Ejemplo de algunas filas aleatorias del dataset etiquetado:\n",
        "train['anger'].sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB7hb7KH2DFK"
      },
      "source": [
        "# Ejemplo de algunas filas aleatorias del dataset no etiquetado\n",
        "target['anger'].sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5aNqEfVzvIv"
      },
      "source": [
        "### Analizar los datos \n",
        "\n",
        "En esta secci√≥n analizaremos el balance de los datos. Para ello se imprime la cantidad de tweets de cada dataset agrupados por la intensidad de sentimiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.117633Z",
          "start_time": "2020-04-07T15:44:21.090703Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5007JRgzvIv",
        "outputId": "7f539863-7d58-4731-f857-50788618b961"
      },
      "source": [
        "for dataset_name in train:\n",
        "    print(f'Dataset: {dataset_name} \\n', train[dataset_name].groupby(['sentiment_intensity']).size())\n",
        "    print('----------------------------------------------------------\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: anger \n",
            " sentiment_intensity\n",
            "high      163\n",
            "low       161\n",
            "medium    617\n",
            "dtype: int64\n",
            "----------------------------------------------------------\n",
            "\n",
            "Dataset: fear \n",
            " sentiment_intensity\n",
            "high      270\n",
            "low       288\n",
            "medium    699\n",
            "dtype: int64\n",
            "----------------------------------------------------------\n",
            "\n",
            "Dataset: joy \n",
            " sentiment_intensity\n",
            "high      195\n",
            "low       219\n",
            "medium    488\n",
            "dtype: int64\n",
            "----------------------------------------------------------\n",
            "\n",
            "Dataset: sadness \n",
            " sentiment_intensity\n",
            "high      197\n",
            "low       210\n",
            "medium    453\n",
            "dtype: int64\n",
            "----------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments = ['anger','sadness','fear','joy']\n",
        "sentiment_intensities = ['high','medium','low']\n",
        "smallest_set = {'anger':161,'sadness':197,'fear':270,'joy':195}\n",
        "def typeCounterByIntensity():\n",
        "  results = { }\n",
        "  for sentiment in sentiments:\n",
        "    data_frame = train[sentiment]\n",
        "    for intensity in sentiment_intensities:\n",
        "      sentiment_df = data_frame[data_frame['sentiment_intensity']==intensity].sample(smallest_set[sentiment],random_state=1)\n",
        "      cv = CountVectorizer(stop_words='english')\n",
        "      cv_fit = cv.fit_transform(sentiment_df.tweet)\n",
        "      df = pd.DataFrame({'token':cv.get_feature_names_out(), ('count'+' '+intensity):cv_fit.toarray().sum(axis=0)})\n",
        "      df = df.sort_values(('count'+' '+intensity),ascending=False)\n",
        "      results[sentiment+ ' ' + intensity]=df\n",
        "  return results\n",
        "\n",
        "results = typeCounterByIntensity()\n"
      ],
      "metadata": {
        "id": "kP0K5j_8PFfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anger_results = results['anger high'].merge(results['anger medium'].merge(results['anger low'],on='token',how='outer'),on='token',how='outer')\n",
        "anger_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "wyjjwRETRXe2",
        "outputId": "e6353a02-3c50-4187-ec3f-beb79538bbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             token  count high  count medium  count low\n",
              "0           fuming        23.0           3.0        NaN\n",
              "1            angry        21.0           7.0        2.0\n",
              "2           people        18.0          14.0        5.0\n",
              "3             just        15.0          21.0       17.0\n",
              "4              don        13.0          10.0       12.0\n",
              "...            ...         ...           ...        ...\n",
              "2101        heaven         NaN           NaN        1.0\n",
              "2102         hello         NaN           NaN        1.0\n",
              "2103  heymanhustle         NaN           NaN        1.0\n",
              "2104     hialeshia         NaN           NaN        1.0\n",
              "2105         zumba         NaN           NaN        1.0\n",
              "\n",
              "[2106 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ba8c647-d219-49ed-90a3-eecefd69c71b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>count high</th>\n",
              "      <th>count medium</th>\n",
              "      <th>count low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fuming</td>\n",
              "      <td>23.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>angry</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>people</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>just</td>\n",
              "      <td>15.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>don</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2101</th>\n",
              "      <td>heaven</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2102</th>\n",
              "      <td>hello</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2103</th>\n",
              "      <td>heymanhustle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2104</th>\n",
              "      <td>hialeshia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2105</th>\n",
              "      <td>zumba</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2106 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ba8c647-d219-49ed-90a3-eecefd69c71b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ba8c647-d219-49ed-90a3-eecefd69c71b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ba8c647-d219-49ed-90a3-eecefd69c71b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sadness_results = results['sadness high'].merge(results['sadness medium'].merge(results['sadness low'],on='token',how='outer'),on='token',how='outer')\n",
        "sadness_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "aUT35ijVVWdt",
        "outputId": "02a8ef4c-776d-497f-8542-31a5f5620954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             token  count high  count medium  count low\n",
              "0       depressing        28.0           1.0        NaN\n",
              "1       depression        26.0           3.0        NaN\n",
              "2              sad        23.0          16.0        2.0\n",
              "3          sadness        16.0           7.0        NaN\n",
              "4          unhappy        15.0          10.0        1.0\n",
              "...            ...         ...           ...        ...\n",
              "2755  granddesigns         NaN           NaN        1.0\n",
              "2756         green         NaN           NaN        1.0\n",
              "2757  griffinlanep         NaN           NaN        1.0\n",
              "2758       grilled         NaN           NaN        1.0\n",
              "2759           „Ç¢„Éã„É°         NaN           NaN        1.0\n",
              "\n",
              "[2760 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2b3f6cb-a516-4611-ae73-91c4ead87973\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>count high</th>\n",
              "      <th>count medium</th>\n",
              "      <th>count low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>depressing</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>depression</td>\n",
              "      <td>26.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sad</td>\n",
              "      <td>23.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sadness</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>unhappy</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2755</th>\n",
              "      <td>granddesigns</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2756</th>\n",
              "      <td>green</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2757</th>\n",
              "      <td>griffinlanep</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2758</th>\n",
              "      <td>grilled</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759</th>\n",
              "      <td>„Ç¢„Éã„É°</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2760 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2b3f6cb-a516-4611-ae73-91c4ead87973')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2b3f6cb-a516-4611-ae73-91c4ead87973 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2b3f6cb-a516-4611-ae73-91c4ead87973');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fear_results = results['fear high'].merge(results['fear medium'].merge(results['fear low'],on='token',how='outer'),on='token',how='outer')\n",
        "fear_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "IBQ5DrI-WP5A",
        "outputId": "c8891555-6b91-42f3-ec15-f90285e119a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              token  count high  count medium  count low\n",
              "0           nervous        36.0           3.0        NaN\n",
              "1         nightmare        26.0           7.0        1.0\n",
              "2           anxiety        26.0           6.0        1.0\n",
              "3             panic        24.0           6.0        NaN\n",
              "4              just        20.0          16.0       19.0\n",
              "...             ...         ...           ...        ...\n",
              "3293     hallelujah         NaN           NaN        1.0\n",
              "3294  hatersbackoff         NaN           NaN        1.0\n",
              "3295         harder         NaN           NaN        1.0\n",
              "3296          happy         NaN           NaN        1.0\n",
              "3297         handle         NaN           NaN        1.0\n",
              "\n",
              "[3298 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4d90846-004c-43d5-b192-5661e10b95c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>count high</th>\n",
              "      <th>count medium</th>\n",
              "      <th>count low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nervous</td>\n",
              "      <td>36.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nightmare</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>anxiety</td>\n",
              "      <td>26.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>panic</td>\n",
              "      <td>24.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>just</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3293</th>\n",
              "      <td>hallelujah</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3294</th>\n",
              "      <td>hatersbackoff</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3295</th>\n",
              "      <td>harder</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3296</th>\n",
              "      <td>happy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3297</th>\n",
              "      <td>handle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3298 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4d90846-004c-43d5-b192-5661e10b95c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4d90846-004c-43d5-b192-5661e10b95c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4d90846-004c-43d5-b192-5661e10b95c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joy_results = results['joy high'].merge(results['joy medium'].merge(results['joy low'],on='token',how='outer'),on='token',how='outer')\n",
        "joy_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "O8ByIjsgXB-h",
        "outputId": "395210cf-3622-42f8-eb26-0db672ae642f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           token  count high  count medium  count low\n",
              "0          happy        39.0          11.0        5.0\n",
              "1           love        36.0           9.0        4.0\n",
              "2            day        31.0           5.0        6.0\n",
              "3          smile        24.0          13.0        4.0\n",
              "4      hilarious        22.0           8.0        1.0\n",
              "...          ...         ...           ...        ...\n",
              "2463   generally         NaN           NaN        1.0\n",
              "2464        gifs         NaN           NaN        1.0\n",
              "2465       girls         NaN           NaN        1.0\n",
              "2466         gkn         NaN           NaN        1.0\n",
              "2467  yungdoujin         NaN           NaN        1.0\n",
              "\n",
              "[2468 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cb0e662-3167-4931-a0dc-2f58115addf7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>count high</th>\n",
              "      <th>count medium</th>\n",
              "      <th>count low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>happy</td>\n",
              "      <td>39.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>love</td>\n",
              "      <td>36.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>day</td>\n",
              "      <td>31.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>smile</td>\n",
              "      <td>24.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hilarious</td>\n",
              "      <td>22.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2463</th>\n",
              "      <td>generally</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2464</th>\n",
              "      <td>gifs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2465</th>\n",
              "      <td>girls</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2466</th>\n",
              "      <td>gkn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2467</th>\n",
              "      <td>yungdoujin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2468 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cb0e662-3167-4931-a0dc-2f58115addf7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cb0e662-3167-4931-a0dc-2f58115addf7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cb0e662-3167-4931-a0dc-2f58115addf7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stZ6ig5hzvIv"
      },
      "source": [
        "### Custom Features \n",
        "\n",
        "Para crear features personalizadas implementaremos nuestros propios Transformers (estandar de scikit para crear nuevas features entre otras cosas). Para esto:\n",
        "\n",
        "1. Creamos nuestra clase Transformer extendiendo BaseEstimator y TransformerMixin. En este ejemplo, definiremos `CharsCountTransformer` que cuenta caracteres relevantes ('!', '?', '#', '@') en los tweets.\n",
        "2. Definimos una funci√≥n c√≥mo `get_relevant_chars` que opera por cada tweet y retorna un arreglo.\n",
        "3. Hacemos un override de la funci√≥n `transform` en donde iteramos por cada tweet, llamamos a la funci√≥n que hicimos antes y agregamos sus resultados a un arreglo. Finalmente lo retornamos.\n",
        "\n",
        "Esto nos facilitar√° el trabajo mas adelante. Una Guia completa de las transformaciones predefinidas en scikit pueden encontrarla [aqu√≠](https://scikit-learn.org/stable/data_transforms.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.128600Z",
          "start_time": "2020-04-07T15:44:21.119624Z"
        },
        "id": "tNPB8zc9zvIw"
      },
      "source": [
        "class CharsCountTransformer(BaseEstimator, TransformerMixin):\n",
        "    def get_relevant_chars(self, tweet):\n",
        "        num_hashtags = tweet.count('#')\n",
        "        num_exclamations = tweet.count('!')\n",
        "        num_interrogations = tweet.count('?')\n",
        "        num_at = tweet.count('@')\n",
        "        return [num_hashtags]\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        chars = []\n",
        "        for tweet in X:\n",
        "            chars.append(self.get_relevant_chars(tweet))\n",
        "\n",
        "        return np.array(chars)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.145564Z",
          "start_time": "2020-04-07T15:44:21.131593Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCQzsuAbzvIw",
        "outputId": "b88e71b4-16f7-491e-8131-212459e65c0d"
      },
      "source": [
        "# Veamos que sucede si ejecutamos el transformer\n",
        "sample = train['anger'].sample(5, random_state = 1).tweet\n",
        "sample_features = CharsCountTransformer().transform(sample)\n",
        "\n",
        "# Se puede verificar que el conteo de s√≠mbolos es consistente con el transformer creado.\n",
        "print(f'Tweet original: {sample.iloc[0]}')\n",
        "print(f'Features creados: {sample_features[0]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet original: @everycolorbot more like every color looks the same #triggered #colorblind \n",
            "Features creados: [2 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments = ['anger','sadness','fear','joy']\n",
        "sentiment_intensities = ['high','medium','low']\n",
        "smallest_set = {'anger':161,'sadness':197,'fear':270,'joy':195}\n",
        "\n",
        "def charCounterByIntensity():\n",
        "  for sentiment in sentiments:\n",
        "    print(\"\\n----\"+sentiment+\"----\")\n",
        "    data_frame = train[sentiment]\n",
        "    for intensity in sentiment_intensities:\n",
        "      sentiment_df = data_frame[data_frame['sentiment_intensity']==intensity].sample(smallest_set[sentiment])\n",
        "      features = CharsCountTransformer().transform(sentiment_df.tweet)\n",
        "      total_count = [0,0,0,0]\n",
        "      for i in range(len(sentiment_df)):\n",
        "        total_count += features[i]\n",
        "      \n",
        "      print(\"#\",\"!\",\"?\",\"@\")\n",
        "      print('total count ' + sentiment + \" \" + intensity +\":\\n\",total_count)\n",
        "charCounterByIntensity()\n"
      ],
      "metadata": {
        "id": "er54FNQRmFSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706dcc27-5c21-4ea1-df62-047395eeb088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----anger----\n",
            "# ! ? @\n",
            "total count anger high:\n",
            " [163  78  23  92]\n",
            "# ! ? @\n",
            "total count anger medium:\n",
            " [120  30  27 136]\n",
            "# ! ? @\n",
            "total count anger low:\n",
            " [186  31  15  86]\n",
            "\n",
            "----sadness----\n",
            "# ! ? @\n",
            "total count sadness high:\n",
            " [221  35  18  73]\n",
            "# ! ? @\n",
            "total count sadness medium:\n",
            " [149  32  23 124]\n",
            "# ! ? @\n",
            "total count sadness low:\n",
            " [250  62  26 118]\n",
            "\n",
            "----fear----\n",
            "# ! ? @\n",
            "total count fear high:\n",
            " [397  67  39 121]\n",
            "# ! ? @\n",
            "total count fear medium:\n",
            " [357  73  40 195]\n",
            "# ! ? @\n",
            "total count fear low:\n",
            " [323  83  34 176]\n",
            "\n",
            "----joy----\n",
            "# ! ? @\n",
            "total count joy high:\n",
            " [303 124   4 144]\n",
            "# ! ? @\n",
            "total count joy medium:\n",
            " [196  43  12 115]\n",
            "# ! ? @\n",
            "total count joy low:\n",
            " [ 70  19  17 113]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharsCountTransformer2(BaseEstimator, TransformerMixin):\n",
        "    def get_relevant_chars(self, tweet):\n",
        "        num_hashtags = tweet.count('#')\n",
        "        num_exclamations = tweet.count('!')\n",
        "        num_interrogations = tweet.count('?')\n",
        "        num_at = tweet.count('@')\n",
        "        num_ast = tweet.count('*')\n",
        "        num_sus = tweet.count('...')\n",
        "        return [num_hashtags, num_exclamations, num_interrogations, num_at, num_ast, num_sus]\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        chars = []\n",
        "        for tweet in X:\n",
        "            chars.append(self.get_relevant_chars(tweet))\n",
        "\n",
        "        return np.array(chars)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "DY127cGYSa_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElongatedWordsCountTransformer(BaseEstimator, TransformerMixin):\n",
        "    def get_relevant_chars(self, tweet):\n",
        "        regex = re.compile(r\"([a-z])\\1{2}\")\n",
        "        num_elon = 0\n",
        "        for word in tweet.split():\n",
        "            if regex.search(word):\n",
        "              num_elon += 1\n",
        "        return [num_elon]\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        words = []\n",
        "        for tweet in X:\n",
        "            words.append(self.get_relevant_chars(tweet))\n",
        "\n",
        "        return np.array(words)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "1s2h2qfvZdxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments = ['anger','sadness','fear','joy']\n",
        "sentiment_intensities = ['high','medium','low']\n",
        "smallest_set = {'anger':161,'sadness':197,'fear':270,'joy':195}\n",
        "\n",
        "def elonCounterByIntensity():\n",
        "  for sentiment in sentiments:\n",
        "    print(\"\\n----\"+sentiment+\"----\")\n",
        "    data_frame = train[sentiment]\n",
        "    for intensity in sentiment_intensities:\n",
        "      sentiment_df = data_frame[data_frame['sentiment_intensity']==intensity].sample(smallest_set[sentiment])\n",
        "      features = ElongatedWordsCountTransformer().transform(sentiment_df.tweet)\n",
        "      total_count = [0]\n",
        "      for i in range(len(sentiment_df)):\n",
        "        total_count += features[i]\n",
        "      \n",
        "      print(\"#\",\"!\",\"?\",\"@\")\n",
        "      print('total count ' + sentiment + \" \" + intensity +\":\\n\",total_count)\n",
        "elonCounterByIntensity()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7KZhGf3aqEr",
        "outputId": "71c23341-5e40-44c7-97c9-2ff7fad4a279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----anger----\n",
            "# ! ? @\n",
            "total count anger high:\n",
            " [3]\n",
            "# ! ? @\n",
            "total count anger medium:\n",
            " [4]\n",
            "# ! ? @\n",
            "total count anger low:\n",
            " [11]\n",
            "\n",
            "----sadness----\n",
            "# ! ? @\n",
            "total count sadness high:\n",
            " [2]\n",
            "# ! ? @\n",
            "total count sadness medium:\n",
            " [7]\n",
            "# ! ? @\n",
            "total count sadness low:\n",
            " [5]\n",
            "\n",
            "----fear----\n",
            "# ! ? @\n",
            "total count fear high:\n",
            " [3]\n",
            "# ! ? @\n",
            "total count fear medium:\n",
            " [4]\n",
            "# ! ? @\n",
            "total count fear low:\n",
            " [3]\n",
            "\n",
            "----joy----\n",
            "# ! ? @\n",
            "total count joy high:\n",
            " [2]\n",
            "# ! ? @\n",
            "total count joy medium:\n",
            " [3]\n",
            "# ! ? @\n",
            "total count joy low:\n",
            " [3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LexiconCountTransformer(BaseEstimator, TransformerMixin):\n",
        "    lexicons = {\n",
        "        'anger':['fuming','angry','people','fucking','fuck','irritate'],\n",
        "        'sadness':['depression','sad','sadness','unhappy','amp','grim'],\n",
        "        'fear':['nervous','nightmare','anxiety','panic','terror','im'],\n",
        "        'joy':['happy','love','smile','hilarious','joyful','great']\n",
        "    }\n",
        "    lexicon_list = []\n",
        "\n",
        "    def set_lexicon_list(self, sentiment):\n",
        "        self.lexicon_list = self.lexicons[sentiment]\n",
        "        return self\n",
        "\n",
        "    def get_relevant_words(self, tweet):\n",
        "        results = [0]*len(self.lexicon_list)\n",
        "        for i in range(len(self.lexicon_list)):\n",
        "            cv = CountVectorizer()\n",
        "            cv_fit = cv.fit_transform([tweet])\n",
        "            df = pd.DataFrame({'token':cv.get_feature_names_out(), 'count':cv_fit.toarray().sum(axis=0)})\n",
        "            present = df[df['token']==self.lexicon_list[i]]\n",
        "            if len(present) > 0:\n",
        "                results[i] = int(df[df['token']==self.lexicon_list[i]]['count'])**2\n",
        "            else:\n",
        "                results[i] = 0\n",
        "        return results\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        words = []\n",
        "        for tweet in X:\n",
        "            words.append(self.get_relevant_words(tweet))\n",
        "\n",
        "        return np.array(words)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "tHjG9znWc9Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos que sucede si ejecutamos el transformer\n",
        "sample = train['anger'].sample(5).tweet\n",
        "sample_features = LexiconCountTransformer().set_lexicon_list('anger').transform(sample)\n",
        "\n",
        "# Se puede verificar que el conteo de s√≠mbolos es consistente con el transformer creado.\n",
        "print(f'Tweet original: {sample.iloc[0]}')\n",
        "print(f'Features creados: {sample_features[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JTAPd-NYBMz",
        "outputId": "0ed2c078-9f21-46de-8ec2-83b049daf139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet original: jamming out to fury in math class wanting to die hbu\n",
            "Features creados: [0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO_yIepczvIx"
      },
      "source": [
        "### Definir la representaci√≥n y el clasificador\n",
        "\n",
        "Para esto, definiremos Pipelines. Un `Pipeline` es una lista de transformaciones y un estimador(clasificador) ubicado al final el cual define el flujo que seguiran nuestros datos dentro del sistema que creemos. Nos permite ejecutar facilmente el mismo proceso sobre todos los datasets que usemos, simplificando as√≠ nuestra programaci√≥n.\n",
        "\n",
        "El pipeline m√°s b√°sico que podemos hacer es transformar el dataset a Bag of Words y despu√©s usar clasificar el BoW usando NaiveBayes:\n",
        "\n",
        "```python\n",
        "    Pipeline([('bow', CountVectorizer()), ('clf', MultinomialNB())])\n",
        "```\n",
        "\n",
        "\n",
        "Ahora, si queremos usar nuestra transformaci√≥n para agregar las features que creamos, usaremos `FeatureUnion`. Esta simplemente concatenar√° los vectores resultantes de ejecutar BoW y los Transformer en un solo vector.\n",
        "\n",
        "```python\n",
        "    Pipeline([('features',FeatureUnion([('bow', CountVectorizer()),\n",
        "                                        ('chars_count',CharsCountTransformer())])),\n",
        "              ('clf', MultinomialNB())])\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDbHjXv-zvIx"
      },
      "source": [
        "Recuerden que cada pipeline representa un sistema de clasificaci√≥n distinto. Por lo mismo, deben instanciar uno por cada problema que resuelvan. De lo contrario, podr√≠an solapar resultados.  Para esto, les recomendamos crear los pipeline en distintas funciones, como la siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "def get_experiment_0_pipeline():\n",
        "\n",
        "    return Pipeline([('features',\n",
        "                      FeatureUnion([('bow', CountVectorizer()),\n",
        "                                    ('chars_count', CharsCountTransformer()),\n",
        "                                    ])), ('clf', MultinomialNB())])"
      ],
      "metadata": {
        "id": "RAkrnaoHdKiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "def get_experiment_1F_pipeline():\n",
        "\n",
        "    return Pipeline([('features',\n",
        "                      FeatureUnion([('bow', CountVectorizer()),\n",
        "                                    ('chars_count', CharsCountTransformer2()),\n",
        "                                    ])), ('clf', MultinomialNB())])"
      ],
      "metadata": {
        "id": "1lZEK6hcSmnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "def get_experiment_2F_pipeline():\n",
        "\n",
        "    return Pipeline([('features',\n",
        "                      FeatureUnion([('bow', CountVectorizer()),\n",
        "                                    ('chars_count', CharsCountTransformer2()),\n",
        "                                    ('elon_words_count', ElongatedWordsCountTransformer()),\n",
        "                                    ])), ('clf', MultinomialNB())])"
      ],
      "metadata": {
        "id": "C-_nQ3oAgW-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.155528Z",
          "start_time": "2020-04-07T15:44:21.149545Z"
        },
        "id": "z_R6tyMCzvIy"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "def get_experiment_3F_pipelines():\n",
        "    pipelines = {}\n",
        "    pipelines['anger'] = Pipeline([('features',\n",
        "                          FeatureUnion([('bow', CountVectorizer()),\n",
        "                                        ('chars_count', CharsCountTransformer2()),\n",
        "                                        ('lexicon_count', LexiconCountTransformer().set_lexicon_list('anger')),\n",
        "                                        ])), ('clf', MultinomialNB())])\n",
        "    pipelines['sadness'] = Pipeline([('features',\n",
        "                          FeatureUnion([('bow', CountVectorizer()),\n",
        "                                        ('chars_count', CharsCountTransformer2()),\n",
        "                                        ('lexicon_count', LexiconCountTransformer().set_lexicon_list('sadness')),\n",
        "                                        ])), ('clf', MultinomialNB())])\n",
        "    pipelines['joy'] = Pipeline([('features',\n",
        "                          FeatureUnion([('bow', CountVectorizer()),\n",
        "                                        ('chars_count', CharsCountTransformer2()),\n",
        "                                        ('lexicon_count', LexiconCountTransformer().set_lexicon_list('joy')),\n",
        "                                        ])), ('clf', MultinomialNB())])\n",
        "    pipelines['fear'] = Pipeline([('features',\n",
        "                          FeatureUnion([('bow', CountVectorizer()),\n",
        "                                        ('chars_count', CharsCountTransformer2()),\n",
        "                                        ('lexicon_count', LexiconCountTransformer().set_lexicon_list('fear')),\n",
        "                                        ])), ('clf', MultinomialNB())])\n",
        "    return pipelines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmMdm98vzvIy"
      },
      "source": [
        "### Ejecutar el pipeline para alg√∫n dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.167498Z",
          "start_time": "2020-04-07T15:44:21.157540Z"
        },
        "scrolled": true,
        "id": "_eX0cEu-zvIz"
      },
      "source": [
        "def run(dataset, dataset_name, pipeline):\n",
        "    \"\"\"Creamos el pipeline y luego lo ejecutamos el pipeline sobre un dataset. \n",
        "    Retorna el modelo ya entrenado mas sus labels asociadas y los scores obtenidos al evaluarlo.\"\"\"\n",
        "\n",
        "    # Dividimos el dataset en train y test, a√∫n no se transforma de Strings a valores num√©ricos.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        dataset.tweet,\n",
        "        dataset.sentiment_intensity,\n",
        "        shuffle=True,\n",
        "        test_size=0.33)\n",
        "    \n",
        "    print(f'# Datos de entrenamiento en dataset {dataset_name}: {len(X_train)}')\n",
        "    print(f'# Datos de testing en dataset {dataset_name}: {len(X_test)}')\n",
        "\n",
        "    # Entrenamos el clasificador (Ejecuta el entrenamiento sobre todo el pipeline). \n",
        "    # En este caso el Bag of Words es el encargado de transformar de Strings a vectores num√©ricos.\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predecimos las probabilidades de intensidad de cada elemento del set de prueba.\n",
        "    predicted_probabilities = pipeline.predict_proba(X_test)\n",
        "\n",
        "    # Obtenemos el orden de las clases aprendidas.\n",
        "    learned_labels = pipeline.classes_\n",
        "    \n",
        "    # Evaluamos:\n",
        "    scores = evaluate(predicted_probabilities, y_test, learned_labels, dataset_name)\n",
        "    return pipeline, learned_labels, scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z96C1ZOfzvIz"
      },
      "source": [
        "### Ejecutar el sistema creado por cada train set\n",
        "\n",
        "Este c√≥digo crea y entrena los 4 sistemas de clasificaci√≥n y luego los evalua. Para los experimentos, pueden copiar este c√≥digo variando el pipeline cuantas veces estimen conveniente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.384119Z",
          "start_time": "2020-04-07T15:44:21.170488Z"
        },
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXAxZBdVzvI0",
        "outputId": "32e30bee-55a1-45c3-8b24-f097f68a9fec"
      },
      "source": [
        "classifiers = []\n",
        "learned_labels_array = []\n",
        "scores_array = []\n",
        "\n",
        "# Por cada nombre_dataset, dataset en train ('anger', 'fear', 'joy', 'sadness')\n",
        "for dataset_name, dataset in train.items():\n",
        "  \n",
        "    # creamos el pipeline\n",
        "    pipeline = get_experiment_0_pipeline()\n",
        "    \n",
        "    # ejecutamos el pipeline sobre el dataset\n",
        "    classifier, learned_labels, scores = run(dataset, dataset_name, pipeline)\n",
        "\n",
        "    # guardamos el clasificador entrenado (en realidad es el pipeline ya entrenado...)\n",
        "    classifiers.append(classifier)\n",
        "\n",
        "    # guardamos las labels aprendidas por el clasificador\n",
        "    learned_labels_array.append(learned_labels)\n",
        "\n",
        "    # guardamos los scores obtenidos\n",
        "    scores_array.append(scores)\n",
        "\n",
        "# print avg scores\n",
        "print(\n",
        "    \"Average scores:\\n\\n\",\n",
        "    \"Average AUC: {0:.3g}\\t Average Kappa: {1:.3g}\\t Average Accuracy: {2:.3g}\"\n",
        "    .format(*np.array(scores_array).mean(axis=0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Datos de entrenamiento en dataset anger: 630\n",
            "# Datos de testing en dataset anger: 311\n",
            "Confusion Matrix for anger:\n",
            "\n",
            "[[  8  46   0]\n",
            " [  6 186   7]\n",
            " [  0  47  11]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.57      0.15      0.24        54\n",
            "      medium       0.67      0.93      0.78       199\n",
            "        high       0.61      0.19      0.29        58\n",
            "\n",
            "    accuracy                           0.66       311\n",
            "   macro avg       0.62      0.42      0.43       311\n",
            "weighted avg       0.64      0.66      0.59       311\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.63\tKappa: 0.163\tAccuracy: 0.659\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset fear: 842\n",
            "# Datos de testing en dataset fear: 415\n",
            "Confusion Matrix for fear:\n",
            "\n",
            "[[ 18  74   2]\n",
            " [ 13 208  15]\n",
            " [  1  57  27]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.56      0.19      0.29        94\n",
            "      medium       0.61      0.88      0.72       236\n",
            "        high       0.61      0.32      0.42        85\n",
            "\n",
            "    accuracy                           0.61       415\n",
            "   macro avg       0.60      0.46      0.48       415\n",
            "weighted avg       0.60      0.61      0.56       415\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.653\tKappa: 0.213\tAccuracy: 0.61\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset joy: 604\n",
            "# Datos de testing en dataset joy: 298\n",
            "Confusion Matrix for joy:\n",
            "\n",
            "[[ 15  47   1]\n",
            " [ 10 154   5]\n",
            " [  0  45  21]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.60      0.24      0.34        63\n",
            "      medium       0.63      0.91      0.74       169\n",
            "        high       0.78      0.32      0.45        66\n",
            "\n",
            "    accuracy                           0.64       298\n",
            "   macro avg       0.67      0.49      0.51       298\n",
            "weighted avg       0.65      0.64      0.59       298\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.713\tKappa: 0.266\tAccuracy: 0.638\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset sadness: 576\n",
            "# Datos de testing en dataset sadness: 284\n",
            "Confusion Matrix for sadness:\n",
            "\n",
            "[[ 14  44   1]\n",
            " [  9 137   5]\n",
            " [  1  61  12]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.58      0.24      0.34        59\n",
            "      medium       0.57      0.91      0.70       151\n",
            "        high       0.67      0.16      0.26        74\n",
            "\n",
            "    accuracy                           0.57       284\n",
            "   macro avg       0.61      0.44      0.43       284\n",
            "weighted avg       0.60      0.57      0.51       284\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.669\tKappa: 0.169\tAccuracy: 0.574\n",
            "------------------------------------------------------\n",
            "\n",
            "Average scores:\n",
            "\n",
            " Average AUC: 0.666\t Average Kappa: 0.203\t Average Accuracy: 0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = []\n",
        "learned_labels_array = []\n",
        "scores_array = []\n",
        "\n",
        "# Por cada nombre_dataset, dataset en train ('anger', 'fear', 'joy', 'sadness')\n",
        "for dataset_name, dataset in train.items():\n",
        "  \n",
        "    # creamos el pipeline\n",
        "    pipeline = get_experiment_1_pipeline()\n",
        "    \n",
        "    # ejecutamos el pipeline sobre el dataset\n",
        "    classifier, learned_labels, scores = run(dataset, dataset_name, pipeline)\n",
        "\n",
        "    # guardamos el clasificador entrenado (en realidad es el pipeline ya entrenado...)\n",
        "    classifiers.append(classifier)\n",
        "\n",
        "    # guardamos las labels aprendidas por el clasificador\n",
        "    learned_labels_array.append(learned_labels)\n",
        "\n",
        "    # guardamos los scores obtenidos\n",
        "    scores_array.append(scores)\n",
        "\n",
        "# print avg scores\n",
        "print(\n",
        "    \"Average scores:\\n\\n\",\n",
        "    \"Average AUC: {0:.3g}\\t Average Kappa: {1:.3g}\\t Average Accuracy: {2:.3g}\"\n",
        "    .format(*np.array(scores_array).mean(axis=0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYQgb0H2Sxrs",
        "outputId": "dea875c3-d952-4821-f2d4-b13b43d2b8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Datos de entrenamiento en dataset anger: 630\n",
            "# Datos de testing en dataset anger: 311\n",
            "Confusion Matrix for anger:\n",
            "\n",
            "[[  6  37   0]\n",
            " [  8 201   8]\n",
            " [  1  39  11]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.40      0.14      0.21        43\n",
            "      medium       0.73      0.93      0.81       217\n",
            "        high       0.58      0.22      0.31        51\n",
            "\n",
            "    accuracy                           0.70       311\n",
            "   macro avg       0.57      0.43      0.44       311\n",
            "weighted avg       0.66      0.70      0.65       311\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.594\tKappa: 0.174\tAccuracy: 0.701\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset fear: 842\n",
            "# Datos de testing en dataset fear: 415\n",
            "Confusion Matrix for fear:\n",
            "\n",
            "[[ 18  64   1]\n",
            " [ 16 209  17]\n",
            " [  1  68  21]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.51      0.22      0.31        83\n",
            "      medium       0.61      0.86      0.72       242\n",
            "        high       0.54      0.23      0.33        90\n",
            "\n",
            "    accuracy                           0.60       415\n",
            "   macro avg       0.56      0.44      0.45       415\n",
            "weighted avg       0.58      0.60      0.55       415\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.644\tKappa: 0.168\tAccuracy: 0.598\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset joy: 604\n",
            "# Datos de testing en dataset joy: 298\n",
            "Confusion Matrix for joy:\n",
            "\n",
            "[[ 18  54   1]\n",
            " [ 14 138  10]\n",
            " [  1  41  21]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.55      0.25      0.34        73\n",
            "      medium       0.59      0.85      0.70       162\n",
            "        high       0.66      0.33      0.44        63\n",
            "\n",
            "    accuracy                           0.59       298\n",
            "   macro avg       0.60      0.48      0.49       298\n",
            "weighted avg       0.59      0.59      0.56       298\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.685\tKappa: 0.227\tAccuracy: 0.594\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset sadness: 576\n",
            "# Datos de testing en dataset sadness: 284\n",
            "Confusion Matrix for sadness:\n",
            "\n",
            "[[  7  55   0]\n",
            " [  9 142   6]\n",
            " [  0  54  11]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.44      0.11      0.18        62\n",
            "      medium       0.57      0.90      0.70       157\n",
            "        high       0.65      0.17      0.27        65\n",
            "\n",
            "    accuracy                           0.56       284\n",
            "   macro avg       0.55      0.40      0.38       284\n",
            "weighted avg       0.56      0.56      0.49       284\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.622\tKappa: 0.101\tAccuracy: 0.563\n",
            "------------------------------------------------------\n",
            "\n",
            "Average scores:\n",
            "\n",
            " Average AUC: 0.636\t Average Kappa: 0.167\t Average Accuracy: 0.614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = []\n",
        "learned_labels_array = []\n",
        "scores_array = []\n",
        "\n",
        "# Por cada nombre_dataset, dataset en train ('anger', 'fear', 'joy', 'sadness')\n",
        "for dataset_name, dataset in train.items():\n",
        "  \n",
        "    # creamos el pipeline\n",
        "    pipeline = get_experiment_2_pipeline()\n",
        "    \n",
        "    # ejecutamos el pipeline sobre el dataset\n",
        "    classifier, learned_labels, scores = run(dataset, dataset_name, pipeline)\n",
        "\n",
        "    # guardamos el clasificador entrenado (en realidad es el pipeline ya entrenado...)\n",
        "    classifiers.append(classifier)\n",
        "\n",
        "    # guardamos las labels aprendidas por el clasificador\n",
        "    learned_labels_array.append(learned_labels)\n",
        "\n",
        "    # guardamos los scores obtenidos\n",
        "    scores_array.append(scores)\n",
        "\n",
        "# print avg scores\n",
        "print(\n",
        "    \"Average scores:\\n\\n\",\n",
        "    \"Average AUC: {0:.3g}\\t Average Kappa: {1:.3g}\\t Average Accuracy: {2:.3g}\"\n",
        "    .format(*np.array(scores_array).mean(axis=0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciS1xq8vgs_Q",
        "outputId": "2d7117e1-d2a9-494a-a646-380226df5151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Datos de entrenamiento en dataset anger: 630\n",
            "# Datos de testing en dataset anger: 311\n",
            "Confusion Matrix for anger:\n",
            "\n",
            "[[  6  43   0]\n",
            " [  8 197   7]\n",
            " [  0  46   4]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.43      0.12      0.19        49\n",
            "      medium       0.69      0.93      0.79       212\n",
            "        high       0.36      0.08      0.13        50\n",
            "\n",
            "    accuracy                           0.67       311\n",
            "   macro avg       0.49      0.38      0.37       311\n",
            "weighted avg       0.60      0.67      0.59       311\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.612\tKappa: 0.072\tAccuracy: 0.666\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset fear: 842\n",
            "# Datos de testing en dataset fear: 415\n",
            "Confusion Matrix for fear:\n",
            "\n",
            "[[ 15  73   2]\n",
            " [ 13 198  16]\n",
            " [  3  68  27]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.48      0.17      0.25        90\n",
            "      medium       0.58      0.87      0.70       227\n",
            "        high       0.60      0.28      0.38        98\n",
            "\n",
            "    accuracy                           0.58       415\n",
            "   macro avg       0.56      0.44      0.44       415\n",
            "weighted avg       0.57      0.58      0.53       415\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.692\tKappa: 0.175\tAccuracy: 0.578\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset joy: 604\n",
            "# Datos de testing en dataset joy: 298\n",
            "Confusion Matrix for joy:\n",
            "\n",
            "[[ 18  59   0]\n",
            " [  7 139   9]\n",
            " [  0  39  27]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.72      0.23      0.35        77\n",
            "      medium       0.59      0.90      0.71       155\n",
            "        high       0.75      0.41      0.53        66\n",
            "\n",
            "    accuracy                           0.62       298\n",
            "   macro avg       0.69      0.51      0.53       298\n",
            "weighted avg       0.66      0.62      0.58       298\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.72\tKappa: 0.289\tAccuracy: 0.617\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset sadness: 576\n",
            "# Datos de testing en dataset sadness: 284\n",
            "Confusion Matrix for sadness:\n",
            "\n",
            "[[  8  64   0]\n",
            " [  6 130   7]\n",
            " [  2  54  13]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.50      0.11      0.18        72\n",
            "      medium       0.52      0.91      0.66       143\n",
            "        high       0.65      0.19      0.29        69\n",
            "\n",
            "    accuracy                           0.53       284\n",
            "   macro avg       0.56      0.40      0.38       284\n",
            "weighted avg       0.55      0.53      0.45       284\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.631\tKappa: 0.115\tAccuracy: 0.532\n",
            "------------------------------------------------------\n",
            "\n",
            "Average scores:\n",
            "\n",
            " Average AUC: 0.664\t Average Kappa: 0.163\t Average Accuracy: 0.598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = []\n",
        "learned_labels_array = []\n",
        "scores_array = []\n",
        "\n",
        "# Por cada nombre_dataset, dataset en train ('anger', 'fear', 'joy', 'sadness')\n",
        "for dataset_name, dataset in train.items():\n",
        "  \n",
        "    # creamos el pipeline\n",
        "    pipeline = get_experiment_3_pipelines()[dataset_name]\n",
        "    \n",
        "    # ejecutamos el pipeline sobre el dataset\n",
        "    classifier, learned_labels, scores = run(dataset, dataset_name, pipeline)\n",
        "\n",
        "    # guardamos el clasificador entrenado (en realidad es el pipeline ya entrenado...)\n",
        "    classifiers.append(classifier)\n",
        "\n",
        "    # guardamos las labels aprendidas por el clasificador\n",
        "    learned_labels_array.append(learned_labels)\n",
        "\n",
        "    # guardamos los scores obtenidos\n",
        "    scores_array.append(scores)\n",
        "\n",
        "# print avg scores\n",
        "print(\n",
        "    \"Average scores:\\n\\n\",\n",
        "    \"Average AUC: {0:.3g}\\t Average Kappa: {1:.3g}\\t Average Accuracy: {2:.3g}\"\n",
        "    .format(*np.array(scores_array).mean(axis=0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLWE9SjjhYBI",
        "outputId": "7114ad04-8951-4e75-a414-c98836101db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Datos de entrenamiento en dataset anger: 630\n",
            "# Datos de testing en dataset anger: 311\n",
            "Confusion Matrix for anger:\n",
            "\n",
            "[[  7  34   0]\n",
            " [  7 194   9]\n",
            " [  0  52   8]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.50      0.17      0.25        41\n",
            "      medium       0.69      0.92      0.79       210\n",
            "        high       0.47      0.13      0.21        60\n",
            "\n",
            "    accuracy                           0.67       311\n",
            "   macro avg       0.55      0.41      0.42       311\n",
            "weighted avg       0.62      0.67      0.61       311\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.602\tKappa: 0.127\tAccuracy: 0.672\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset fear: 842\n",
            "# Datos de testing en dataset fear: 415\n",
            "Confusion Matrix for fear:\n",
            "\n",
            "[[ 17  70   5]\n",
            " [ 18 198  16]\n",
            " [  1  47  43]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.47      0.18      0.27        92\n",
            "      medium       0.63      0.85      0.72       232\n",
            "        high       0.67      0.47      0.55        91\n",
            "\n",
            "    accuracy                           0.62       415\n",
            "   macro avg       0.59      0.50      0.51       415\n",
            "weighted avg       0.60      0.62      0.59       415\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.683\tKappa: 0.276\tAccuracy: 0.622\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset joy: 604\n",
            "# Datos de testing en dataset joy: 298\n",
            "Confusion Matrix for joy:\n",
            "\n",
            "[[ 17  52   1]\n",
            " [ 11 133   7]\n",
            " [  2  50  25]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.57      0.24      0.34        70\n",
            "      medium       0.57      0.88      0.69       151\n",
            "        high       0.76      0.32      0.45        77\n",
            "\n",
            "    accuracy                           0.59       298\n",
            "   macro avg       0.63      0.48      0.49       298\n",
            "weighted avg       0.62      0.59      0.55       298\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.739\tKappa: 0.247\tAccuracy: 0.587\n",
            "------------------------------------------------------\n",
            "\n",
            "# Datos de entrenamiento en dataset sadness: 576\n",
            "# Datos de testing en dataset sadness: 284\n",
            "Confusion Matrix for sadness:\n",
            "\n",
            "[[ 15  46   2]\n",
            " [ 10 139   8]\n",
            " [  1  48  15]]\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         low       0.58      0.24      0.34        63\n",
            "      medium       0.60      0.89      0.71       157\n",
            "        high       0.60      0.23      0.34        64\n",
            "\n",
            "    accuracy                           0.60       284\n",
            "   macro avg       0.59      0.45      0.46       284\n",
            "weighted avg       0.59      0.60      0.54       284\n",
            "\n",
            "Scores:\n",
            "\n",
            "AUC:  0.666\tKappa: 0.2\tAccuracy: 0.595\n",
            "------------------------------------------------------\n",
            "\n",
            "Average scores:\n",
            "\n",
            " Average AUC: 0.672\t Average Kappa: 0.213\t Average Accuracy: 0.619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-21T19:37:43.169737Z",
          "start_time": "2019-08-21T19:37:43.166744Z"
        },
        "id": "IUKwcde_zvI0"
      },
      "source": [
        "### Predecir los target set y crear la submission\n",
        "\n",
        "Aqu√≠ predecimos los target set usando los clasificadores creados y creamos los archivos de las submissions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.392097Z",
          "start_time": "2020-04-07T15:44:21.386114Z"
        },
        "id": "mWDUoSmbzvI1"
      },
      "source": [
        "def predict_target(dataset, classifier, labels):\n",
        "    # Predecir las probabilidades de intensidad de cada elemento del target set.\n",
        "    predicted = pd.DataFrame(classifier.predict_proba(dataset.tweet), columns=labels)\n",
        "    \n",
        "    # Agregar ids\n",
        "    predicted['id'] = dataset.id.values\n",
        "    # Reordenar las columnas\n",
        "    predicted = predicted[['id', 'low', 'medium', 'high']]\n",
        "    return predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T15:44:21.588573Z",
          "start_time": "2020-04-07T15:44:21.394094Z"
        },
        "scrolled": true,
        "id": "5CJ4PTwZzvI1"
      },
      "source": [
        "predicted_target = {}\n",
        "\n",
        "# Crear carpeta ./predictions\n",
        "if (not os.path.exists('./predictions')):\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "else:\n",
        "    # Eliminar predicciones anteriores:\n",
        "    shutil.rmtree('./predictions')\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "# por cada target set:\n",
        "for idx, key in enumerate(target):\n",
        "    # Predecirlo\n",
        "    predicted_target[key] = predict_target(target[key], classifiers[idx],\n",
        "                                           learned_labels_array[idx])\n",
        "    # Guardar predicciones en archivos separados. \n",
        "    predicted_target[key].to_csv('./predictions/{}-pred.txt'.format(key),\n",
        "                                 sep='\\t',\n",
        "                                 header=False,\n",
        "                                 index=False)\n",
        "\n",
        "# Crear archivo zip\n",
        "a = shutil.make_archive('predictions', 'zip', './predictions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCAyJIj8nTlU"
      },
      "source": [
        "## **7. Resultados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAYwupS3naYX"
      },
      "source": [
        "    Muestre y analice sus resultados aqu√≠\n",
        "\n",
        "A continuaci√≥n una tabla de ejemplo para mostrar los resultados.  En este caso s√≥lo est√° el experimento del baseline m√°s otro clasificador, pero ustedes debiesen generar una mayor cantidad de experimentos. \n",
        "\n",
        "| No. | Approach                       || Dataset   | AUC   | Kappa | Accuracy |\n",
        "|-----|--------------------------------||-----------|-------|-------|----------|\n",
        "|     | Features        | Clasifier     |           |       |       |          |\n",
        "| 0   | bow+chars_count | MultinomialNB | anger     | 0.622 | 0.163 | 0.688    |\n",
        "|     |                 |               | fear      | 0.597 | 0.091 | 0.559    |\n",
        "|     |                 |               | joy       | 0.728 | 0.251 | 0.601    |\n",
        "|     |                 |               | sadness   | 0.645 | 0.166 | 0.581    |\n",
        "|     |                 |               |**average**| 0.648 | 0.168 | 0.607    |\n",
        "| 1   | tus features    | tu clasifier  | anger     |       |       |          |\n",
        "|     |                 |               | fear      |       |       |          |\n",
        "|     |                 |               | joy       |       |       |          |\n",
        "|     |                 |               | sadness   |       |       |          |\n",
        "|     |                 |               |**average**|       |       |          |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqlew0iizvI1"
      },
      "source": [
        "## **8. Conclusiones**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFTikGbszZuc"
      },
      "source": [
        "    Escriba aqu√≠ sus conclusiones"
      ]
    }
  ]
}